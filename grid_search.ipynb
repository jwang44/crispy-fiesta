{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grid search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/crispy-fiesta/blob/main/grid_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFVPh3OjIgkF"
      },
      "source": [
        "This notebook implements the grid search for feature and model parameter together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhYkxNMosYcz",
        "outputId": "18178f94-a8ff-4a13-a75a-0143d171a783"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3YXcam7SI-H"
      },
      "source": [
        "## Load the data and get basic features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVrTh5Fdsqcg"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OMqYMZNsq_-"
      },
      "source": [
        "train = pd.read_csv('./train.csv',engine='python')\r\n",
        "test = pd.read_csv('./test.csv',engine='python')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjdGixmNss4K"
      },
      "source": [
        "X_train = train.body  # train texts\r\n",
        "y_train = train.subreddit # train subreddits\r\n",
        "X_test = test.body  # test texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95NKm9YPtJ_d"
      },
      "source": [
        "from sklearn.preprocessing import Normalizer, LabelEncoder\r\n",
        "from sklearn.feature_extraction import text\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XFoTwA_s2B-",
        "outputId": "b30e4286-c1e2-4577-ab2e-328d14b9a4c4"
      },
      "source": [
        "# transform target labels to values\r\n",
        "le = LabelEncoder()\r\n",
        "y_train_num = le.fit_transform(y_train.values) # convert category from string to numerical (!!!!! update the variables in kcross fold)\r\n",
        "\r\n",
        "# vectorize word count\r\n",
        "vectorizer = CountVectorizer()\r\n",
        "vectors_train = vectorizer.fit_transform(X_train)\r\n",
        "vectors_test = vectorizer.transform(X_test)\r\n",
        "\r\n",
        "normalizer_train = Normalizer()\r\n",
        "vectors_train= normalizer_train.transform(vectors_train)\r\n",
        "vectors_test= normalizer_train.transform(vectors_test)\r\n",
        "\r\n",
        "# print(vectorizer.get_feature_names())\r\n",
        "print(vectors_train.shape)\r\n",
        "print(vectors_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 15365)\n",
            "(1378, 15365)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkJsrQzH1qAD",
        "outputId": "98a1e179-f667-4834-c30a-295f3ee24e32"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\r\n",
        "from nltk import word_tokenize\r\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOD25ysB1x1o",
        "outputId": "25d18c38-d37e-4e9f-c4d3-45f1db095122"
      },
      "source": [
        "# put it all together: remove stop words and punctuation, tfidf, lemmatization, normalization\r\n",
        "stop_words = text.ENGLISH_STOP_WORDS\r\n",
        "\r\n",
        "def get_wordnet_pos(word):\r\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\r\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\r\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\r\n",
        "                \"N\": wordnet.NOUN,\r\n",
        "                \"V\": wordnet.VERB,\r\n",
        "                \"R\": wordnet.ADV}\r\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\r\n",
        "\r\n",
        "class New_LemmaTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl = WordNetLemmatizer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.lemmatize(t,pos =get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "tf_idf_transformer = TfidfTransformer()\r\n",
        "vectorizer = CountVectorizer(stop_words = stop_words, tokenizer = New_LemmaTokenizer(), ngram_range=(1, 2)) #unigram+bigram:ngram_range=(1, 2), only bigram:ngram_range=(2, 2)\r\n",
        "vectors_train_stop_Lemma = vectorizer.fit_transform(X_train)\r\n",
        "vectors_train_stop_tfidf_Lemma = tf_idf_transformer.fit_transform(vectors_train_stop_Lemma)\r\n",
        "vectors_test_stop_Lemma = vectorizer.transform(X_test)\r\n",
        "vectors_test_stop_tfidf_Lemma = tf_idf_transformer.transform(vectors_test_stop_Lemma)\r\n",
        "vectors_train_stop_tfidf_Lemma = normalizer_train.transform(vectors_train_stop_tfidf_Lemma)\r\n",
        "vectors_test_stop_tfidf_Lemma = normalizer_train.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "normalizer_l1 = Normalizer(norm='l1')\r\n",
        "vectors_train_stop_tfidf_l1_Lemma = normalizer_l1.transform(vectors_train_stop_tfidf_Lemma)\r\n",
        "vectors_test_stop_tfidf_l1_Lemma = normalizer_l1.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "\r\n",
        "#print(vectorizer.get_feature_names())\r\n",
        "print(vectors_train_stop_tfidf_Lemma.shape)\r\n",
        "#print(vectors_test_stop_tfidf_Lemma.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make', 'u'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1999, 70414)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcDWLcpSSQUX"
      },
      "source": [
        "## Grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzvYQTytAXZ"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, mutual_info_classif, f_classif, SelectFpr, SelectFwe, SelectFdr, RFE, RFECV, SelectFromModel\r\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vg5DZCdDirH"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q08-xoAUDjf1"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.svm import SVC, LinearSVC\r\n",
        "\r\n",
        "from sklearn.model_selection import KFold, cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHTQfaQKFQLE"
      },
      "source": [
        "### N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9rZr3iyFBVf",
        "outputId": "9e4e9e1c-3d3e-4539-d592-8928750ac07d"
      },
      "source": [
        "# grid search for the N-gram range \r\n",
        "pipeline = Pipeline([\r\n",
        "    ('vect', CountVectorizer(stop_words = stop_words)),\r\n",
        "    ('tfidf', TfidfTransformer()),\r\n",
        "    ('normalize',Normalizer()),\r\n",
        "    ('select', RFECV(estimator=LinearSVC(),step=2800))\r\n",
        "])\r\n",
        "\r\n",
        "parameters = {  \r\n",
        "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (2, 2), (3, 3))\r\n",
        "}\r\n",
        "gs_model = GridSearchCV(pipeline, parameters, cv=10, n_jobs=-1)\r\n",
        "gs_model = gs_model.fit(X_train, y_train_num)\r\n",
        "print(gs_model.best_score_)\r\n",
        "for param_name in sorted(parameters.keys()):\r\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9474773869346734\n",
            "vect__ngram_range: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyZdRcHUaKv3"
      },
      "source": [
        "### linearSVC without lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BprYRez7RqL8",
        "outputId": "5a861db2-3aea-4b84-dc1b-77cb781b0ff2"
      },
      "source": [
        "# grid search for linearSVC without lemmatization\r\n",
        "pipeline = Pipeline([\r\n",
        "    ('vect', CountVectorizer()),\r\n",
        "    ('tfidf', TfidfTransformer()),\r\n",
        "    ('normalize',Normalizer()),\r\n",
        "    ('select', SelectPercentile()),\r\n",
        "    ('clf', LinearSVC()),\r\n",
        "])\r\n",
        "\r\n",
        "parameters = {  \r\n",
        "    'vect__ngram_range': ((1, 1), (1, 2)),  # use unigram or unigram+bigram\r\n",
        "    'vect__stop_words':(None, text.ENGLISH_STOP_WORDS), # whether to remove stopwords\r\n",
        "    'tfidf__use_idf': (True, False), #whether to use idf\r\n",
        "    'normalize__norm': ('l1','l2'),  #L1 or L2 normalization\r\n",
        "    'select__percentile': (20, 40, 60, 80, 100),  # selected percentile of the original features\r\n",
        "    'select__score_func': (chi2, f_classif,mutual_info_classif), # scoring function type\r\n",
        "    'clf__C': (0.01, 0.1, 1, 10, 100) # Regularization parameter\r\n",
        "}\r\n",
        "gs_model = GridSearchCV(pipeline, parameters, cv=10, n_jobs=-1)\r\n",
        "gs_model = gs_model.fit(X_train, y_train_num)\r\n",
        "print(gs_model.best_score_)\r\n",
        "for param_name in sorted(parameters.keys()):\r\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9514824120603015\n",
            "clf__C: 10\n",
            "normalize__norm: 'l2'\n",
            "select__percentile: 100\n",
            "select__score_func: <function chi2 at 0x7f54485fc320>\n",
            "tfidf__use_idf: True\n",
            "vect__ngram_range: (1, 2)\n",
            "vect__stop_words: frozenset({'yourself', 'ltd', 'afterwards', 'only', 'already', 'everyone', 'move', 'by', 'themselves', 'someone', 'detail', 'hereafter', 'becomes', 'down', 'then', 'rather', 'thin', 'though', 'ie', 'over', 'latter', 'sometime', 'on', 'un', 'with', 'ten', 'through', 'meanwhile', 'no', 'whom', 'becoming', 'most', 'sixty', 'very', 'beforehand', 'whence', 'will', 'because', 'thereby', 'go', 'below', 'were', 'an', 'whereby', 'much', 're', 'whoever', 'always', 'sometimes', 'found', 'has', 'some', 'she', 'see', 'during', 'without', 'but', 'de', 'last', 'top', 'these', 'everything', 'others', 'mostly', 'there', 'may', 'could', 'put', 'how', 'those', 'onto', 'except', 'four', 'anyway', 'among', 'be', 'its', 'cry', 'enough', 'whatever', 'thence', 'else', 'which', 'none', 'himself', 'never', 'moreover', 'call', 'twenty', 'whose', 'herein', 'couldnt', 'whole', 'mine', 'whereafter', 'whereupon', 'nothing', 'before', 'a', 'otherwise', 'find', 'until', 'it', 'therein', 'was', 'whenever', 'under', 'empty', 'describe', 'eleven', 'nor', 'interest', 'least', 'latterly', 'fill', 'via', 'nine', 'they', 'that', 'thereupon', 'within', 'as', 'however', 'own', 'ever', 'anyhow', 'sincere', 'towards', 'please', 'throughout', 'too', 'name', 'than', 'this', 'often', 'fire', 'perhaps', 'wherever', 'the', 'amount', 'where', 'anywhere', 'hence', 'namely', 'give', 'him', 'beyond', 'can', 'once', 'yourselves', 'us', 'her', 'co', 'would', 'them', 'seems', 'mill', 'we', 'thus', 'for', 'each', 'thereafter', 'although', 'less', 'behind', 'also', 'being', 'you', 'keep', 'front', 'myself', 'seeming', 'might', 'get', 'cannot', 'amongst', 'neither', 'further', 'have', 'around', 'back', 'inc', 'whereas', 'next', 'former', 'wherein', 'anyone', 'take', 'to', 'so', 'fifteen', 'noone', 'whither', 'bottom', 'eg', 'somehow', 'two', 'other', 'another', 'upon', 'what', 'about', 'seem', 'several', 'indeed', 'one', 'off', 'fifty', 'many', 'herself', 'third', 'across', 'nobody', 'are', 'forty', 'con', 'above', 'become', 'hasnt', 'itself', 'hers', 'nevertheless', 'few', 'something', 'when', 'besides', 'five', 'therefore', 'eight', 'from', 'against', 'should', 'thru', 'well', 'if', 'more', 'amoungst', 'at', 'my', 'beside', 'been', 'hereby', 'part', 'while', 'ourselves', 'made', 'their', 'seemed', 'full', 'such', 'all', 'anything', 'now', 'our', 'everywhere', 'thick', 'hereupon', 'done', 'out', 'am', 'ours', 'into', 'whether', 'do', 'formerly', 'why', 'twelve', 'between', 'three', 'i', 'etc', 'is', 'even', 'yet', 'somewhere', 'yours', 'system', 'bill', 'hundred', 'cant', 'and', 'had', 'both', 'nowhere', 'again', 'due', 'first', 'per', 'side', 'almost', 'either', 'your', 'together', 'serious', 'six', 'still', 'after', 'along', 'or', 'must', 'any', 'toward', 'me', 'here', 'elsewhere', 'in', 'became', 'up', 'of', 'show', 'not', 'he', 'same', 'alone', 'his', 'since', 'every', 'who'})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDwDlxfXvNp9"
      },
      "source": [
        "### linearSVC with lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgPYf5OkDW9K",
        "outputId": "aa475175-3deb-4332-a01a-60475d439a68"
      },
      "source": [
        "# grid search for linearSVC with lemmatization\r\n",
        "pipeline = Pipeline([\r\n",
        "    ('tfidf', TfidfTransformer()),\r\n",
        "    ('normalize',Normalizer()),\r\n",
        "    ('select', SelectPercentile()),\r\n",
        "    ('clf', LinearSVC()),\r\n",
        "])\r\n",
        "\r\n",
        "parameters = {\r\n",
        "    'tfidf__use_idf': (True, False),#whether to use idf\r\n",
        "    'normalize__norm': ('l1','l2'),#L1 or L2 normalization\r\n",
        "    'select__percentile': (20, 40, 60, 80, 100), # selected percentile of the original features\r\n",
        "    'select__score_func': (chi2, f_classif，mutual_info_classif)# scoring function type\r\n",
        "    'clf__C': (0.01, 0.1, 1, 10, 100) # Regularization parameter\r\n",
        "}\r\n",
        "gs_model = GridSearchCV(pipeline, parameters, cv=10, n_jobs=-1)\r\n",
        "gs_model = gs_model.fit(vectors_train_stop_Lemma, y_train_num)\r\n",
        "print(gs_model.best_score_)\r\n",
        "for param_name in sorted(parameters.keys()):\r\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.940969849246231\n",
            "clf__C: 1\n",
            "normalize__norm: 'l2'\n",
            "select__percentile: 40\n",
            "select__score_func: <function chi2 at 0x7fa8ddef2290>\n",
            "tfidf__use_idf: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwFiv2RukP6o"
      },
      "source": [
        "### RBF SVC with lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbKYyslskPlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98375aa6-6b84-41c5-ff84-afadf88eca59"
      },
      "source": [
        "# grid search for RBFSVC with lemmatization\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('normalize',Normalizer()),\n",
        "    ('select', SelectPercentile()),\n",
        "    ('clf', SVC()),\n",
        "])\n",
        "\n",
        "parameters = {\n",
        "    'tfidf__use_idf': (True, False),#whether to use idf\n",
        "    'normalize__norm': ('l1','l2'),#L1 or L2 normalization\n",
        "    'select__percentile': (20, 40, 60, 80, 100), # selected percentile of the original features\n",
        "    'select__score_func': (chi2, f_classif，mutual_info_classif)# scoring function type\n",
        "    'clf__C': (0.01, 0.1, 1, 10, 100) # Regularization parameter\n",
        "}\n",
        "gs_model = GridSearchCV(pipeline, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_stop_tfidf_Lemma, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9319748743718591\n",
            "clf__C: 10\n",
            "normalize__norm: 'l2'\n",
            "select__percentile: 100\n",
            "select__score_func: <function chi2 at 0x7f27ac7b0320>\n",
            "tfidf__use_idf: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmg8wcjx0gs4"
      },
      "source": [
        "### MultinomialNB with lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qAd64HAM6NU",
        "outputId": "8994fbf9-56bc-4a97-ab41-7270cfd3259d"
      },
      "source": [
        "# grid search for MultinomialNB with lemmatization\r\n",
        "pipeline = Pipeline([\r\n",
        "    ('tfidf', TfidfTransformer()),\r\n",
        "    ('normalize',Normalizer()),\r\n",
        "    ('select', SelectPercentile()),\r\n",
        "    ('clf', MultinomialNB())\r\n",
        "])\r\n",
        "\r\n",
        "parameters = {   \r\n",
        "    'tfidf__use_idf': (True, False),#whether to use idf\r\n",
        "    'normalize__norm': ('l1','l2'),#L1 or L2 normalization\r\n",
        "    'select__percentile': (20, 40, 60, 80, 100), # selected percentile of the original features\r\n",
        "    'select__score_func': (chi2, f_classif，mutual_info_classif)# scoring function type\r\n",
        "    'clf__alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2) # smoothing parameter\r\n",
        "}\r\n",
        "gs_model = GridSearchCV(pipeline, parameters, cv=10, n_jobs=-1)\r\n",
        "gs_model = gs_model.fit(vectors_train_stop_Lemma, y_train_num)\r\n",
        "print(gs_model.best_score_)\r\n",
        "for param_name in sorted(parameters.keys()):\r\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9309723618090452\n",
            "clf__alpha: 0.1\n",
            "normalize__norm: 'l2'\n",
            "select__percentile: 60\n",
            "select__score_func: <function chi2 at 0x7fa8ddef2290>\n",
            "tfidf__use_idf: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJvsvSar0mVY"
      },
      "source": [
        "### BernoulliNB with lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3onFEHGwNuGo",
        "outputId": "5a20d913-b3cb-43a3-f0d0-5f9a8f7ac3ed"
      },
      "source": [
        "# grid search for BernoulliNB with lemmatization\r\n",
        "pipeline = Pipeline([\r\n",
        "    ('tfidf', TfidfTransformer()),\r\n",
        "    ('normalize',Normalizer()),\r\n",
        "    ('select', SelectPercentile()),\r\n",
        "    ('clf', BernoulliNB())\r\n",
        "])\r\n",
        "\r\n",
        "parameters = {   \r\n",
        "    'tfidf__use_idf': (True, False),#whether to use idf\r\n",
        "    'normalize__norm': ('l1','l2'),#L1 or L2 normalization\r\n",
        "    'select__percentile': (20, 40, 60, 80, 100), # selected percentile of the original features\r\n",
        "    'select__score_func': (chi2, f_classif，mutual_info_classif)# scoring function type\r\n",
        "    'clf__alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2) # smoothing parameter\r\n",
        "}\r\n",
        "gs_model = GridSearchCV(pipeline, parameters, cv=10, n_jobs=-1)\r\n",
        "gs_model = gs_model.fit(vectors_train_stop_Lemma, y_train_num)\r\n",
        "print(gs_model.best_score_)\r\n",
        "for param_name in sorted(parameters.keys()):\r\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9094623115577889\n",
            "clf__alpha: 1e-05\n",
            "normalize__norm: 'l2'\n",
            "select__percentile: 60\n",
            "select__score_func: <function chi2 at 0x7fa8ddef2290>\n",
            "tfidf__use_idf: True\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}