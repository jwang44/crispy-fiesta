{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature selection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/crispy-fiesta/blob/main/Ngram_selection_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhYkxNMosYcz",
        "outputId": "cbfb6c99-3ae2-41c4-ab01-4d3767cdc993"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3YXcam7SI-H"
      },
      "source": [
        "## Load the data and get basic features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVrTh5Fdsqcg"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OMqYMZNsq_-"
      },
      "source": [
        "train = pd.read_csv('./train.csv',engine='python')\r\n",
        "test = pd.read_csv('./test.csv',engine='python')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjdGixmNss4K"
      },
      "source": [
        "X_train = train.body  # train texts\r\n",
        "y_train = train.subreddit # train subreddits\r\n",
        "X_test = test.body  # test texts"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95NKm9YPtJ_d"
      },
      "source": [
        "from sklearn.preprocessing import Normalizer, LabelEncoder\r\n",
        "from sklearn.feature_extraction import text\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XFoTwA_s2B-",
        "outputId": "79446b2d-83f9-410f-f8fb-4e50f4173373"
      },
      "source": [
        "# transform target labels to values\r\n",
        "le = LabelEncoder()\r\n",
        "y_train_num = le.fit_transform(y_train.values) # convert category from string to numerical (!!!!! update the variables in kcross fold)\r\n",
        "\r\n",
        "# vectorize word count\r\n",
        "vectorizer = CountVectorizer()\r\n",
        "vectors_train = vectorizer.fit_transform(X_train)\r\n",
        "vectors_test = vectorizer.transform(X_test)\r\n",
        "\r\n",
        "normalizer_train = Normalizer()\r\n",
        "vectors_train= normalizer_train.transform(vectors_train)\r\n",
        "vectors_test= normalizer_train.transform(vectors_test)\r\n",
        "\r\n",
        "# print(vectorizer.get_feature_names())\r\n",
        "print(vectors_train.shape)\r\n",
        "print(vectors_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 15365)\n",
            "(1378, 15365)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkJsrQzH1qAD",
        "outputId": "54a94183-ef47-4903-d724-24ccf9a678a8"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\r\n",
        "from nltk import word_tokenize\r\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOD25ysB1x1o",
        "outputId": "0753f9d9-766d-48b8-f176-5e204b16e045"
      },
      "source": [
        "# put it all together: remove stop words and punctuation, tfidf, lemmatization, normalization\r\n",
        "stop_words = text.ENGLISH_STOP_WORDS\r\n",
        "\r\n",
        "def get_wordnet_pos(word):\r\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\r\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\r\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\r\n",
        "                \"N\": wordnet.NOUN,\r\n",
        "                \"V\": wordnet.VERB,\r\n",
        "                \"R\": wordnet.ADV}\r\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\r\n",
        "\r\n",
        "class New_LemmaTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl = WordNetLemmatizer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.lemmatize(t,pos =get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "tf_idf_transformer = TfidfTransformer()\r\n",
        "vectorizer = CountVectorizer(stop_words = stop_words, tokenizer = New_LemmaTokenizer(), ngram_range=(1, 2)) #unigram+bigram:ngram_range=(1, 2), only bigram:ngram_range=(2, 2)\r\n",
        "vectors_train_stop_tfidf_Lemma = vectorizer.fit_transform(X_train)\r\n",
        "vectors_train_stop_tfidf_Lemma = tf_idf_transformer.fit_transform(vectors_train_stop_tfidf_Lemma)\r\n",
        "vectors_test_stop_tfidf_Lemma = vectorizer.transform(X_test)\r\n",
        "vectors_test_stop_tfidf_Lemma = tf_idf_transformer.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "vectors_train_stop_tfidf_Lemma = normalizer_train.transform(vectors_train_stop_tfidf_Lemma)\r\n",
        "vectors_test_stop_tfidf_Lemma = normalizer_train.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "\r\n",
        "#print(vectorizer.get_feature_names())\r\n",
        "print(vectors_train_stop_tfidf_Lemma.shape)\r\n",
        "print(vectors_test_stop_tfidf_Lemma.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make', 'u'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1999, 70414)\n",
            "(1378, 70414)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oBLHbwe13Uw",
        "outputId": "05077e84-6b78-453a-e864-d350aefbc52d"
      },
      "source": [
        "# remove stopwords and punctuation, tfidf, stemming, normalization\r\n",
        "stop_words = text.ENGLISH_STOP_WORDS\r\n",
        "\r\n",
        "class StemTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl =PorterStemmer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.stem(t) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "tf_idf_transformer = TfidfTransformer()\r\n",
        "vectorizer = CountVectorizer(stop_words = stop_words, tokenizer=StemTokenizer(),ngram_range=(1, 2)) #unigram+bigram:ngram_range=(1, 2), only bigram:ngram_range=(2, 2)\r\n",
        "vectors_train_stop_tfidf_stem = vectorizer.fit_transform(X_train)\r\n",
        "vectors_train_stop_tfidf_stem = tf_idf_transformer.fit_transform(vectors_train_stop_tfidf_stem)\r\n",
        "vectors_test_stop_tfidf_stem = vectorizer.transform(X_test)\r\n",
        "vectors_test_stop_tfidf_stem = tf_idf_transformer.transform(vectors_test_stop_tfidf_stem)\r\n",
        "vectors_train_stop_tfidf_stem = normalizer_train.transform(vectors_train_stop_tfidf_stem)\r\n",
        "vectors_test_stop_tfidf_stem = normalizer_train.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stop_tfidf_stem.shape)\r\n",
        "print(vectors_test_stop_tfidf_stem.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1999, 73597)\n",
            "(1378, 73597)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcDWLcpSSQUX"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzvYQTytAXZ"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, mutual_info_classif, f_classif, SelectFpr, SelectFwe, SelectFdr, RFE, RFECV, SelectFromModel\r\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aigDmX5vOJA"
      },
      "source": [
        "### 13.2.1 chi2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iAF8SklN6_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede2af2a-bd8e-42f9-bb2c-6fff32eed016"
      },
      "source": [
        "# choose one: SelectPercentile percent%, selectkbest abolute number\r\n",
        "select = SelectPercentile(chi2, percentile=60)\r\n",
        "vectors_train_Lemma_X2 = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_X2 = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_X2.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 42248)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wfWxVDLwIgJ"
      },
      "source": [
        "### 13.2.2 mutual info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5hcm_khwIIc",
        "outputId": "7fcb29db-b58d-47b1-f093-1d0df5fc4b31"
      },
      "source": [
        "select = SelectKBest(mutual_info_classif, k=6000)\r\n",
        "vectors_train_Lemma_mutual = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_mutual = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_mutual.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 6000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiZEnhPZ0HnK"
      },
      "source": [
        "### 13.2.3 F score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LCiPkB6Q3jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4426107a-16ab-4bfd-a8d0-3057565bb5a8"
      },
      "source": [
        "select = SelectPercentile(f_classif, percentile=60)\r\n",
        "vectors_train_Lemma_X2 = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_X2 = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_X2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 42248)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K159Gmtz0Aww",
        "outputId": "65ec0d3a-b8fd-403b-baff-e19ca125525d"
      },
      "source": [
        "select = SelectKBest(f_classif, k=6000)\r\n",
        "vectors_train_Lemma_F = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_F = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_F.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 6000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjmQ7tSiSGsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96731ccb-958c-43df-f226-93d0b56f95c1"
      },
      "source": [
        "select = SelectPercentile(f_classif, percentile=60)\r\n",
        "vectors_train_stem_X2 = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_X2 = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_X2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 44158)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz0kpHEp4JrN",
        "outputId": "02c2313d-7a9e-4b1b-ae10-c8bf4d8fbaeb"
      },
      "source": [
        "select = SelectKBest(f_classif, k=5000)\r\n",
        "vectors_train_stem_F = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_F = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_F.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNY9UPfohXAh"
      },
      "source": [
        "### 13.2.4 FPR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CrHP_mShXWV",
        "outputId": "6ad4922e-cd16-46ce-e9cc-f3037f5cfc32"
      },
      "source": [
        "select = SelectFpr()\r\n",
        "vectors_train_Lemma_FPR = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_FPR = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "vectors_train_Lemma_FPR.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 2602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsmNj4QLjol3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57811416-45a0-4807-bcf8-08f1d2fca45d"
      },
      "source": [
        "select = SelectFpr()\r\n",
        "vectors_train_stem_FPR = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_FPR = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "vectors_train_stem_FPR.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 2770)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMy4Tp48j0nn"
      },
      "source": [
        "### 13.2.5 FDR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2K05LInjy3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d39f745-4432-40b0-dc84-bf7025b93eea"
      },
      "source": [
        "select = SelectFdr()\r\n",
        "vectors_train_Lemma_FDR = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_FDR = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "vectors_train_Lemma_FDR.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 1013)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea3uI8_fiex7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd12465-57fb-4b09-b15f-e96bb440ab27"
      },
      "source": [
        "select = SelectFdr()\r\n",
        "vectors_train_stem_FDR = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_FDR = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "vectors_train_stem_FDR.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 1064)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ovjGEulUlv"
      },
      "source": [
        "### 13.2.6 FWE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eizM4rbzh3gC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf094b5-89bf-4adb-d5e4-2af58be4e2b2"
      },
      "source": [
        "select = SelectFwe()\r\n",
        "vectors_train_Lemma_FWE = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_FWE = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "vectors_train_Lemma_FWE.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 507)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dht3JAVlplI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443af7f9-f4dd-40ac-c2b2-4b750ea2b96e"
      },
      "source": [
        "select = SelectFwe()\r\n",
        "vectors_train_stem_FWE = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_FWE = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "vectors_train_stem_FWE.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 523)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4imy8E_6ALI"
      },
      "source": [
        "### 13.3 Recursive feature elimination (runs super slow, maybe run this after setting max_features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGqifNt8XY7"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.svm import SVC, LinearSVC\r\n",
        "\r\n",
        "from sklearn.model_selection import KFold, cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndYrr7lLUPo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "8d9fd03d-31c6-4178-e1e9-495d1de6e1f9"
      },
      "source": [
        "estimator = LinearSVC()\r\n",
        "select = RFECV(estimator, step=98,scoring='accuracy')\r\n",
        "vectors_train_Lemma_RFESVC = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_RFESVC = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_RFESVC.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-684999012f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvectors_train_Lemma_RFESVC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_train_stop_tfidf_Lemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvectors_test_Lemma_RFESVC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_test_stop_tfidf_Lemma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_train_Lemma_RFECV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vectors_train_Lemma_RFECV' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2rkgQ_OW2H-"
      },
      "source": [
        "estimator = LinearSVC()\r\n",
        "select = RFECV(estimator, step=85,scoring='accuracy')\r\n",
        "vectors_train_stem_RFESVC = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_RFESVC = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_RFESVC.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W39u3IvUYa-q"
      },
      "source": [
        "estimator = LogisticRegression()\r\n",
        "select = RFECV(estimator, step=98,scoring='accuracy')\r\n",
        "vectors_train_Lemma_RFELR = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_RFELR = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_RFELR.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVjen15SY5X9"
      },
      "source": [
        "estimator = LogisticRegression()\r\n",
        "select = RFECV(estimator, step=85,scoring='accuracy')\r\n",
        "vectors_train_stem_RFELR = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_RFELR = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_RFELR.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A40g9do-ZqjJ"
      },
      "source": [
        "estimator = MultinomialNB()\r\n",
        "select = RFECV(estimator, step=98,scoring='accuracy')\r\n",
        "vectors_train_Lemma_RFEMNB = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_RFEMNB = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_RFEMNB.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf-xuvLUbOm2"
      },
      "source": [
        "estimator = MultinomialNB()\r\n",
        "select = RFECV(estimator, step=85,scoring='accuracy')\r\n",
        "vectors_train_stem_RFEMNB = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_RFEMNB = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_RFEMNB.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Io3x5mTa2Zn"
      },
      "source": [
        "estimator = DecisionTreeClassifier()\r\n",
        "select = RFECV(estimator, step=98,scoring='accuracy')\r\n",
        "vectors_train_Lemma_RFEDT = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_RFEDT = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_RFEDT.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRRuTja_Z1XM"
      },
      "source": [
        "estimator = DecisionTreeClassifier()\r\n",
        "select = RFECV(estimator, step=85,scoring='accuracy')\r\n",
        "vectors_train_stem_RFEDT = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_RFEDT = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_RFEDT.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8AqYnSs57BU"
      },
      "source": [
        "'''estimator = LinearSVC()\r\n",
        "select = RFE(estimator, n_features_to_select=5000, step=0.1)\r\n",
        "vectors_train_Lemma_RFE = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_RFE = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_RFE.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVwxAGmm6scn"
      },
      "source": [
        "'''estimator = LinearSVC()\r\n",
        "select = RFE(estimator, n_features_to_select=5000, step=0.1)\r\n",
        "vectors_train_stem_RFESVC = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_RFESVC = select.transform(vectors_test_stop_tfidf_stem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OIvmZHu6z52"
      },
      "source": [
        "### 13.4.1 selectfrommodel L1 norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBeC2asR6ycf",
        "outputId": "5b3e106e-5673-41c9-ae32-7d3ed35a5c92"
      },
      "source": [
        "estimator = LinearSVC(C=10, penalty=\"l1\",dual=False)\r\n",
        "select = SelectFromModel(estimator,max_features=5000)\r\n",
        "vectors_train_Lemma_SFML1 = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_SFML1 = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_SFML1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 2091)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LcRUVHh9EA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01da2eac-02a9-4d32-fce4-953b0f81ccd8"
      },
      "source": [
        "estimator = LinearSVC(C=10, penalty=\"l1\",dual=False)\r\n",
        "select = SelectFromModel(estimator,max_features=5000)\r\n",
        "vectors_train_stem_SFML1 = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_SFML1 = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_SFML1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 2064)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A40q_6BkgLzb"
      },
      "source": [
        "### 13.4.2 selectfrommodel tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlCpRznsc3O8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99883c04-2b72-45c8-c773-6048de7925c7"
      },
      "source": [
        "clf = ExtraTreesClassifier()\r\n",
        "clf = clf.fit(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "model = SelectFromModel(clf, prefit=True)\r\n",
        "vectors_train_Lemma_SFMtree = model.transform(vectors_train_stop_tfidf_Lemma)\r\n",
        "vectors_train_Lemma_SFMtree.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 9466)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kBgGpDLfTXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889199a4-79f6-482a-8f83-901134789bc1"
      },
      "source": [
        "clf = ExtraTreesClassifier()\r\n",
        "clf = clf.fit(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "model = SelectFromModel(clf, prefit=True)\r\n",
        "vectors_train_stem_SFMtree = model.transform(vectors_train_stop_tfidf_stem)\r\n",
        "vectors_train_stem_SFMtree.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 9776)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4bpJ3t0TMnS"
      },
      "source": [
        "## Experiment on sklearn models (with NGRAM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L41zKhUPVj2l"
      },
      "source": [
        "### Find the best set of features\n",
        "We have 16 sets in total\n",
        "\n",
        "\n",
        "The best are \n",
        "\n",
        "vectors_train_Lemma_X2\n",
        "\n",
        "vectors_train_Lemma_F\n",
        "\n",
        "vectors_train_Lemma_SFML1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZQ1dRU4yIpa",
        "outputId": "4ae62430-67f9-48c0-e63a-7f96f21e80a3"
      },
      "source": [
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_X2, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_stem_X2, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_mutual, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_stem_mutual, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_F, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_stem_F, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FPR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_stem_FPR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FDR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_stem_FDR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FWE, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_stem_FWE, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_SFML1, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_stem_SFML1, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_SFMtree, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_stem_SFMtree, y_train_num, cv=10)\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9459798994974875\n",
            "0.9449748743718593\n",
            "0.934464824120603\n",
            "0.930462311557789\n",
            "0.9469748743718593\n",
            "0.9449773869346734\n",
            "0.9384698492462311\n",
            "0.9424723618090451\n",
            "0.9214572864321608\n",
            "0.927467336683417\n",
            "0.8869422110552764\n",
            "0.8869422110552764\n",
            "0.9484748743718594\n",
            "0.9464723618090451\n",
            "0.938464824120603\n",
            "0.9339623115577889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctlyl4oiUzMf",
        "outputId": "c150de98-62ac-49b8-ae20-a9c0504268b3"
      },
      "source": [
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_X2, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_stem_X2, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_mutual, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_stem_mutual, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_F, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_stem_F, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FPR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_stem_FPR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FDR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_stem_FDR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FWE, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_stem_FWE, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_SFML1, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_stem_SFML1, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_SFMtree, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_stem_SFMtree, y_train_num, cv=10)\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9364798994974877\n",
            "0.9354798994974877\n",
            "0.9289748743718593\n",
            "0.9289723618090452\n",
            "0.9374773869346734\n",
            "0.9309748743718593\n",
            "0.9329723618090451\n",
            "0.927467336683417\n",
            "0.9079522613065327\n",
            "0.9109572864321608\n",
            "0.8764422110552765\n",
            "0.8764422110552765\n",
            "0.9274698492462312\n",
            "0.9264698492462312\n",
            "0.9304723618090451\n",
            "0.926469849246231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xreyyyy0fa3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d5a303-9ebe-4f51-9b32-d10eded9ab5f"
      },
      "source": [
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_X2, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_stem_X2, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_mutual, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_stem_mutual, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_F, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_stem_F, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FPR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_stem_FPR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FDR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_stem_FDR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FWE, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_stem_FWE, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_SFML1, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_stem_SFML1, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_SFMtree, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_stem_SFMtree, y_train_num, cv=10)\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9179673366834171\n",
            "0.9209648241206029\n",
            "0.9164673366834171\n",
            "0.9144648241206029\n",
            "0.9329723618090451\n",
            "0.928967336683417\n",
            "0.9159698492462311\n",
            "0.9214623115577888\n",
            "0.8879497487437185\n",
            "0.8814522613065326\n",
            "0.839929648241206\n",
            "0.839929648241206\n",
            "0.926469849246231\n",
            "0.9324673366834171\n",
            "0.9229698492462312\n",
            "0.9234648241206029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq5zBLuWWSQH"
      },
      "source": [
        "### Grid search\n",
        "The best features:\n",
        "\n",
        "vectors_train_Lemma_X2\n",
        "\n",
        "vectors_train_Lemma_F\n",
        "\n",
        "vectors_train_Lemma_SFML1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrmAJbRtXGNC"
      },
      "source": [
        "#### vectors_train_Lemma_X2\n",
        "Best models: LinearSVM, MultiNB, BernouliNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB20XzS3FqBL"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IzciLosEMMi",
        "outputId": "009a4511-3ac7-4266-9278-f491f7b39bd6"
      },
      "source": [
        "model = LinearSVC()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_X2, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9459798994974875\n",
            "C: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZxIyqcWQC6u",
        "outputId": "91c67e44-2b55-47b6-ee9c-bbb8b0113a45"
      },
      "source": [
        "model = MultinomialNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2), \n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_X2, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9554849246231155\n",
            "alpha: 1e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6eUbXm6QHID",
        "outputId": "bad67195-46d0-4695-9b60-eeca98628fa8"
      },
      "source": [
        "model = BernoulliNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_X2, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9469773869346734\n",
            "alpha: 1e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQn11XdNXc89"
      },
      "source": [
        "#### vectors_train_Lemma_F\n",
        "Best model: MultiNB, LinearSVM, BernouliNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzPswnO0XrO_"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mqy1F4cXrPL",
        "outputId": "5bfad9f3-bbda-4efb-94a0-83baea4ab90b"
      },
      "source": [
        "model = LinearSVC()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_F, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9469748743718593\n",
            "C: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYZmNzgMXrPN",
        "outputId": "2992cf18-1a92-4b49-a14b-fb48dacd402c"
      },
      "source": [
        "model = MultinomialNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2), \n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_F, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9639874371859296\n",
            "alpha: 1e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1zYdzDxXrPO",
        "outputId": "85b884b3-0049-4f8e-8811-fcfbcd4fb05e"
      },
      "source": [
        "model = BernoulliNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_F, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9594824120603015\n",
            "alpha: 1e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4zY3GidX5ak"
      },
      "source": [
        "#### vectors_train_Lemma_SFML1\n",
        "Best model: MultiNB, LinearSVM, BernouliNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v2HbixzX8GN"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjO6eBlQX8GY",
        "outputId": "58800e3b-7307-40fb-96bc-b13ae296c84e"
      },
      "source": [
        "model = LinearSVC()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_SFML1, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9594874371859297\n",
            "C: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TjSc2XjX8Gb",
        "outputId": "488d4d01-bf36-417f-951c-b4e1497db209"
      },
      "source": [
        "model = MultinomialNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2), \n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_SFML1, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9439773869346734\n",
            "alpha: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEHjQk3iX8Gb",
        "outputId": "2e2b7e6a-5024-496f-acf8-16d95b1a3176"
      },
      "source": [
        "model = BernoulliNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_SFML1, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9519874371859297\n",
            "alpha: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBZ16L91cGK7"
      },
      "source": [
        "### Best model: LinearSVM on vectors_train_Lemma_SFML1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qVb0ydkdAS3"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z3MyfeQVs7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3854f5db-7c2c-4002-b3ec-dba902a8c0c5"
      },
      "source": [
        "model = LinearSVC(C=10)\n",
        "model.fit(vectors_train_Lemma_SFML1, y_train_num)\n",
        "cross_val_score(model, vectors_train_Lemma_SFML1, y_train_num, cv=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.94      , 0.97      , 0.96      , 0.955     , 0.945     ,\n",
              "       0.96      , 0.985     , 0.955     , 0.95      , 0.97487437])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IFZ5fY6V_Ca"
      },
      "source": [
        "model = LinearSVC(C=10)\n",
        "model.fit(vectors_train_Lemma_SFML1, y_train_num)\n",
        "y_pred = model.predict(vectors_test_Lemma_SFML1)\n",
        "y_pred = le.inverse_transform(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz9rCLvRkKDB"
      },
      "source": [
        "#### Write results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYiVSRFSiKw-"
      },
      "source": [
        "result = pd.DataFrame({'id': test.id, 'subreddit': y_pred})\n",
        "result.to_csv(\"result.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfs8FKWxWIbM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "271d8910-4903-433e-9682-337ccd311e85"
      },
      "source": [
        "pred_csv = pd.read_csv('result.csv',engine='python')\n",
        "pred_csv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>anime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id subreddit\n",
              "0   0   science\n",
              "1   1   science\n",
              "2   2     anime\n",
              "3   3   science\n",
              "4   4   science"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv-LNm10CaLk"
      },
      "source": [
        "### Second Best model: MultiNB on vectors_train_Lemma_F"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uK_TB7_CaLo"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwCBQu6CCaLp",
        "outputId": "b070ac8e-5438-494e-a1b2-49d85d1040b1"
      },
      "source": [
        "model = MultinomialNB(alpha=1e-5)\n",
        "# model.fit(vectors_train_Lemma_F, y_train_num)\n",
        "cross_val_score(model, vectors_train_Lemma_F, y_train_num, cv=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96      , 0.985     , 0.95      , 0.975     , 0.94      ,\n",
              "       0.965     , 0.98      , 0.955     , 0.955     , 0.97487437])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vCDdoN6CaLq"
      },
      "source": [
        "model = MultinomialNB(alpha=1e-5)\n",
        "model.fit(vectors_train_Lemma_F, y_train_num)\n",
        "y_pred = model.predict(vectors_test_Lemma_F)\n",
        "y_pred = le.inverse_transform(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acrbVwmaCaLq"
      },
      "source": [
        "#### Write results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcAJg9XFCaLr"
      },
      "source": [
        "result = pd.DataFrame({'id': test.id, 'subreddit': y_pred})\n",
        "result.to_csv(\"result.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FA1Jr0nrCaLs",
        "outputId": "ed988845-1c55-48a4-ca49-018b47980825"
      },
      "source": [
        "pred_csv = pd.read_csv('result.csv',engine='python')\n",
        "pred_csv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>laptop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id subreddit\n",
              "0   0   science\n",
              "1   1   science\n",
              "2   2    laptop\n",
              "3   3   science\n",
              "4   4   science"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGhP_egBrddl"
      },
      "source": [
        "## Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDIGPtwxXuSg"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras import utils"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5FvomoQtCJi"
      },
      "source": [
        "# x_train = vectors_train_Lemma_X2\n",
        "# x_test = vectors_test_Lemma_X2\n",
        "\n",
        "# x_train = vectors_train_Lemma_mutual\n",
        "# x_test = vectors_test_Lemma_mutual\n",
        "\n",
        "# x_train = vectors_train\n",
        "# x_test = vectors_test\n",
        "\n",
        "x_train = vectors_train_stop_tfidf_Lemma\n",
        "x_test = vectors_test_stop_tfidf_Lemma\n",
        "\n",
        "x_train = x_train.toarray()\n",
        "x_test = x_test.toarray()\n",
        "\n",
        "num_classes = len(np.unique(y_train_num))\n",
        "y_train = utils.to_categorical(y_train_num, num_classes)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EIVxwipXuSj"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 4"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGA7hY_FXuSj"
      },
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(x_train.shape[1],)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs9VJf5GXuSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f45ba25-85a8-4390-fc69-194291bf8012"
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "57/57 [==============================] - 11s 187ms/step - loss: 1.3618 - accuracy: 0.5301 - val_loss: 1.1172 - val_accuracy: 0.5050\n",
            "Epoch 2/4\n",
            "57/57 [==============================] - 10s 183ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9100\n",
            "Epoch 3/4\n",
            "57/57 [==============================] - 10s 184ms/step - loss: 3.5160e-04 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9150\n",
            "Epoch 4/4\n",
            "57/57 [==============================] - 10s 184ms/step - loss: 1.6110e-04 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17WMi5zGi_lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4d6f15-e05b-49e4-f4e2-fcf91f6a5f8c"
      },
      "source": [
        "y_test = model.predict(x_test, batch_size, verbose=1)\n",
        "y_classes = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
        "y_pred = le.inverse_transform(y_classes)\n",
        "result = pd.DataFrame({'id': test.id, 'subreddit': y_pred})\n",
        "result.to_csv(\"result.csv\", index=False)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 2s 48ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfEC39db4aUx"
      },
      "source": [
        "## Estimate test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuymKwho5lJ2",
        "outputId": "48cb1b48-0b51-4cb9-a744-00e84d97b54d"
      },
      "source": [
        "result_df = pd.read_csv('result.csv')\n",
        "result_df = result_df['subreddit']\n",
        "error = 0\n",
        "for i in range(1, len(result_df)-1):\n",
        "  if result_df[i]==result_df[i-1] or result_df[i]==result_df[i+1]:\n",
        "    continue\n",
        "  error = error + 1\n",
        "accu = (len(result_df)-error) / len(result_df)\n",
        "accu"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9346879535558781"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    }
  ]
}