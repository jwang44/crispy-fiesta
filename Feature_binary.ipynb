{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_binary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "012IjyNqMK1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9c3a90c-0c08-4cbe-a554-19370932d6d6"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE_hJ2-On_8X"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from  collections import  Counter"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGy8MxtKlWxv"
      },
      "source": [
        "train = pd.read_csv('./train.csv',engine='python')\n",
        "test = pd.read_csv('./test.csv',engine='python')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHibPzaDTeVo"
      },
      "source": [
        "X_train = train.body  # train texts\n",
        "y_train = train.subreddit # train subreddits\n",
        "X_test = test.body  # test texts"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "PUpknna2qA7E",
        "outputId": "49a43571-4b37-4a84-d422-2f2974feaf5d"
      },
      "source": [
        "a=Counter(y_train)\r\n",
        "dic = {number: value for number, value in a.items()}\r\n",
        "x = [\"Science\",\"laptop\",\"samsung\",\"tennis\",\"anime\"]\r\n",
        "y = []\r\n",
        "for i in dic.keys():\r\n",
        "  y.append(dic.get(i))\r\n",
        "for j in range(5):\r\n",
        "  y[j]=y[j]/len(y_train)\r\n",
        "df = pd.DataFrame(y, x)\r\n",
        "\r\n",
        "plt.bar(x,y,align='center')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXCloN6pnqQr"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj2WEwNHdAfM"
      },
      "source": [
        "###Processing based on sk-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qJTvw3DMtG4"
      },
      "source": [
        "from sklearn.preprocessing import Normalizer, LabelEncoder, OneHotEncoder\r\n",
        "from sklearn.feature_extraction import text\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2vtasvRWkeM",
        "outputId": "ed3f3610-5581-419d-cc49-3e6a00970c1a"
      },
      "source": [
        "# transform target labels to values\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train.values)\n",
        "\n",
        "# vectorize word count\n",
        "vectorizer = CountVectorizer()\n",
        "vectors_train = vectorizer.fit_transform(X_train)\n",
        "vectors_test = vectorizer.transform(X_test)\n",
        "vectors_train = vectors_train.todense()\n",
        "vectors_test = vectors_test.todense()\n",
        "\n",
        "# onehot encoding\n",
        "onehot = OneHotEncoder(handle_unknown = 'ignore')\n",
        "vectors_train = onehot.fit_transform(vectors_train)\n",
        "vectors_test = onehot.transform(vectors_test)\n",
        "\n",
        "# print(vectorizer.get_feature_names())\n",
        "print(vectors_train.shape)\n",
        "print(vectors_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 35729)\n",
            "(1378, 35729)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLGRP9vElqgx"
      },
      "source": [
        "# **Binary**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB-6DE9AlG9r"
      },
      "source": [
        "vectorizer = CountVectorizer(binary=True)\r\n",
        "vectors_train_binary = vectorizer.fit_transform(X_train)\r\n",
        "vectors_test_binary = vectorizer.transform(X_test)\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lMh3F7M3SuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d20c7a0c-abf8-4bc4-9db6-14f45b30acd7"
      },
      "source": [
        "# remove stop words\r\n",
        "stop_words = text.ENGLISH_STOP_WORDS\r\n",
        "vectorizer = CountVectorizer(stop_words = stop_words)\r\n",
        "vectors_train_stop = vectorizer.fit_transform(X_train)\r\n",
        "vectors_test_stop = vectorizer.transform(X_test)\r\n",
        "\r\n",
        "normalizer_train = Normalizer()\r\n",
        "vectors_train_stop= normalizer_train.transform(vectors_train_stop)\r\n",
        "vectors_test_stop = normalizer_train.transform(vectors_test_stop)\r\n",
        "print(vectors_train_stop.shape)\r\n",
        "print(vectors_test_stop.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 15079)\n",
            "(1378, 15079)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llzfTbCj3svy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a03c3c-b579-44d4-98a4-75bda3ac5f83"
      },
      "source": [
        "# tf-idf\r\n",
        "tf_idf_vectorizer = TfidfVectorizer()\r\n",
        "vectors_train_idf = tf_idf_vectorizer.fit_transform(X_train)\r\n",
        "vectors_test_idf = tf_idf_vectorizer.transform(X_test)\r\n",
        "vectors_train_idf= normalizer_train.transform(vectors_train_idf)\r\n",
        "vectors_test_idf = normalizer_train.transform(vectors_test_idf)\r\n",
        "print(vectors_train_idf.shape)\r\n",
        "print(vectors_test_idf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 15365)\n",
            "(1378, 15365)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z915xw1Hc6s9"
      },
      "source": [
        "### Processing based on nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EDORAHscEv-",
        "outputId": "d3c4abf7-ed8a-46a3-ab9f-cef5d8842c7e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL8yUINtfBzX"
      },
      "source": [
        "####Stemming\n",
        "features: `vector_train_stem`, `vector_test_stem`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7XpLsfP4qiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c7da3b-7294-49c0-bffd-3716a4005736"
      },
      "source": [
        "# stemming\r\n",
        "class StemTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl =PorterStemmer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.stem(t) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "vectorizer = CountVectorizer(tokenizer=StemTokenizer())\r\n",
        "vectors_train_stem = vectorizer.fit_transform(X_train)\r\n",
        "vectors_test_stem = vectorizer.transform(X_test)\r\n",
        "vectors_train_stem= normalizer_train.transform(vectors_train_stem)\r\n",
        "vectors_test_stem = normalizer_train.transform(vectors_test_stem)\r\n",
        "print(vectors_train_stem.shape)\r\n",
        "print(vectors_test_stem.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 8727)\n",
            "(1378, 8727)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lDtjGaCe9mt"
      },
      "source": [
        "#### Lemmatization\n",
        "features: `vector_train_Lemma`, `vector_test_Lemma`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-9TOxOl5WsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "0c04bc08-970a-436d-f185-061854db76f4"
      },
      "source": [
        "# Lemmatization\r\n",
        "def get_wordnet_pos(word):\r\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\r\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\r\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\r\n",
        "                \"N\": wordnet.NOUN,\r\n",
        "                \"V\": wordnet.VERB,\r\n",
        "                \"R\": wordnet.ADV}\r\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\r\n",
        "  \r\n",
        "class New_LemmaTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl = WordNetLemmatizer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.lemmatize(t,pos =get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "vectorizer = CountVectorizer(tokenizer=New_LemmaTokenizer())\r\n",
        "vectors_train_Lemma = vectorizer.fit_transform(X_train)\r\n",
        "vectors_test_Lemma = vectorizer.transform(X_test)\r\n",
        "vectors_train_Lemma= normalizer_train.transform(vectors_train_Lemma)\r\n",
        "vectors_test_Lemma = normalizer_train.transform(vectors_test_Lemma)\r\n",
        "print(vectors_train_Lemma.shape)\r\n",
        "print(vectors_test_Lemma.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6bf04b880d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNew_LemmaTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mvectors_train_Lemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mvectors_test_Lemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6bf04b880d29>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNew_LemmaTokenizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m      \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwnl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m      \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'WordNetLemmatizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVbRxM6qe5n9"
      },
      "source": [
        "#### Put it all together\n",
        "features: `vector_train_stop_Lemma`, `vector_test_stop_Lemma`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xyxvw6QAEP8",
        "outputId": "560c9883-5b01-4bcb-b7d8-b45a6b06fadb"
      },
      "source": [
        "# put it all together: remove stopwords, tfidf, punctuation, lemmatization, normalization\r\n",
        "stop_words = text.ENGLISH_STOP_WORDS\r\n",
        "\r\n",
        "def get_wordnet_pos(word):\r\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\r\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\r\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\r\n",
        "                \"N\": wordnet.NOUN,\r\n",
        "                \"V\": wordnet.VERB,\r\n",
        "                \"R\": wordnet.ADV}\r\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\r\n",
        "\r\n",
        "class New_LemmaTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl = WordNetLemmatizer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.lemmatize(t,pos =get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "tf_idf_transformer = TfidfTransformer()\r\n",
        "vectorizer = CountVectorizer(stop_words = stop_words,tokenizer=New_LemmaTokenizer())\r\n",
        "vectors_train_stop_Lemma = vectorizer.fit_transform(X_train)\r\n",
        "vectors_train_stop_Lemma = tf_idf_transformer.fit_transform(vectors_train_stop_Lemma)\r\n",
        "\r\n",
        "vectors_test_stop_Lemma = vectorizer.transform(X_test)\r\n",
        "vectors_test_stop_Lemma = tf_idf_transformer.transform(vectors_test_stop_Lemma)\r\n",
        "vectors_train_stop_Lemma = normalizer_train.transform(vectors_train_stop_Lemma)\r\n",
        "vectors_test_stop_Lemma = normalizer_train.transform(vectors_test_stop_Lemma)\r\n",
        "\r\n",
        "# print(vectorizer.get_feature_names())\r\n",
        "print(vectors_train_stop_Lemma.shape)\r\n",
        "print(vectors_test_stop_Lemma.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make', 'u'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1999, 9779)\n",
            "(1378, 9779)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJXs8wYkmbab"
      },
      "source": [
        "# **put it all together binary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX0gfO5GmTre"
      },
      "source": [
        "# put it all together: remove stopwords, punctuation, lemmatization, \r\n",
        "stop_words = text.ENGLISH_STOP_WORDS\r\n",
        "\r\n",
        "def get_wordnet_pos(word):\r\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\r\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\r\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\r\n",
        "                \"N\": wordnet.NOUN,\r\n",
        "                \"V\": wordnet.VERB,\r\n",
        "                \"R\": wordnet.ADV}\r\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\r\n",
        "\r\n",
        "class New_LemmaTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl = WordNetLemmatizer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.lemmatize(t,pos =get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "vectorizer = CountVectorizer(stop_words = stop_words,tokenizer=New_LemmaTokenizer(),binary=True)\r\n",
        "vectors_train_stop_Lemma_binary = vectorizer.fit_transform(X_train)\r\n",
        "vectors_test_stop_Lemma_binary = vectorizer.transform(X_test)\r\n",
        "\r\n",
        "\r\n",
        "# print(vectorizer.get_feature_names())\r\n",
        "# print(vectors_train_stop_Lemma_binary)\r\n",
        "print(vectors_test_stop_Lemma_binary.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymF0ztmLnbGq"
      },
      "source": [
        "## Experiments with models in sk-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH-sQOatGy54"
      },
      "source": [
        "vectors_train，vectors_test是加了onehot的，vectors_train_stop_Lemma是把几种处理都加上的，target是y_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PccMQje5G0wq"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMEu17OWG_qy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0b6bfc-5cf4-4ad4-c7d8-f85b9aa7a4b4"
      },
      "source": [
        "X_train = vectors_train_stop_Lemma\n",
        "y_train = y_train\n",
        "X_test = vectors_test_stop_Lemma\n",
        "# y_test unknown\n",
        "model = BernoulliNB()\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9409704852426213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-2Gt9mxNfyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e7f8554-9ac7-4f1c-9913-191b80ac6468"
      },
      "source": [
        "X_train = vectors_train\n",
        "y_train = y_train\n",
        "X_test = vectors_test\n",
        "# y_test unknown\n",
        "model = BernoulliNB()\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9074537268634317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm5JthkuOxfP"
      },
      "source": [
        "## Kfold cv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym2wjVFJPyhl"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "model = LinearSVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjLrCRIVOwn-"
      },
      "source": [
        "X = vectors_train_stop_Lemma\n",
        "y = y_train\n",
        "# X_test = vectors_test_stop_Lemma\n",
        "# y_test unknown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Lb1SuWNzg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "35679af8-d64c-4b7e-9852-49058a24d88e"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"test accu: \", model.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-25e5e0afa2c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test accu: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;31m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                     raise KeyError(\n\u001b[0;32m-> 1316\u001b[0;31m                         \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m                         \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                         \u001b[0;34mf\"The following labels were missing: {not_found}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([  22,   28,   59,   64,   87,\\n            ...\\n            1951, 1955, 1982, 1992, 1995],\\n           dtype='int64', length=178). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guvT3RTzGgxk"
      },
      "source": [
        "## Bernoulli NB model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUmRiQt-oF5e"
      },
      "source": [
        "import time\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMSndDpV918Z"
      },
      "source": [
        "class Bernoulli_NB():\r\n",
        "  def __init__(self, LaplaceSmoothing = True):\r\n",
        "    self.LaplaceSmoothing = LaplaceSmoothing\r\n",
        "    self.Prob_Y = None      # P(Y)\r\n",
        "    self.Prob_X_Y = None     # P(xj|Y)\r\n",
        "    self.Prob_X_Y = None     # P(xj|Y)\r\n",
        "    self.n_class = 0\r\n",
        "    self.w0 = None\r\n",
        "    self.w = None\r\n",
        "    self.Ytarget = None\r\n",
        "\r\n",
        "\r\n",
        "  def ProbY(self, Y):\r\n",
        "    # calculate P(Y=1) and P(Y=0)\r\n",
        "    ProbY = np.zeros((1,2))\r\n",
        "    #print('shape',np.shape(Y))\r\n",
        "    ProbY[0,1] = np.sum(Y)/np.shape(Y)\r\n",
        "    ProbY[0,0] = 1 - ProbY[0,1]\r\n",
        "    return ProbY\r\n",
        "\r\n",
        "  def ProbX_Yi(self, X, Y, label):\r\n",
        "    # calculte P(xj=1|Yi=1)\r\n",
        "    rows,cols = X.shape       # feature shape\r\n",
        "    numerator = np.zeros(cols)    # initialize numerator\r\n",
        "\r\n",
        "    # xj=1 and Yi=1\r\n",
        "    for n in range(rows):\r\n",
        "      if Y[n] == label:\r\n",
        "        numerator += X[n,:]\r\n",
        "    # Yi=1\r\n",
        "    denominator = np.count_nonzero(Y == label)\r\n",
        "    # Laplace Smoothing\r\n",
        "    if(self.LaplaceSmoothing):\r\n",
        "      numerator += 1\r\n",
        "      denominator += 2\r\n",
        "    # P(xj=1|Yi=1)\r\n",
        "    prob = numerator/denominator\r\n",
        "    return prob    \r\n",
        "\r\n",
        "  def fit(self, X, Y):\r\n",
        "    print('----------------------start fitting---------------------')\r\n",
        "    t1 = time.time()\r\n",
        "\r\n",
        "    rows,cols = X.shape              # feature shape\r\n",
        "    self.n_class = len(np.unique(Y))       # number of classes\r\n",
        "    self.Prob_Y = np.zeros((self.n_class,2))   # initialize P(Y)\r\n",
        "    self.Prob_X_Y = np.zeros((self.n_class,2,cols)) # initialize P(x|Y)\r\n",
        "    c = np.zeros((self.n_class,cols))       # rows:class cols:xj\r\n",
        "    d = np.zeros((self.n_class,cols))       # rows:class cols:xj\r\n",
        "    self.w0 = np.zeros((1,self.n_class))     # [w0Y1,w0Y2,...]\r\n",
        "    self.w = np.zeros((self.n_class,cols))    # [(w1,w2,...)Y1;\r\n",
        "                            # (w1,w2,...)Y2]\r\n",
        "    self.Ytarget = np.unique(Y)\r\n",
        "    Y_index = 0\r\n",
        "    for Yi in self.Ytarget:\r\n",
        "      Y_onevsall = np.where(Y == Yi, 1, 0)    # only have 2 classes: Yi(1) & notYi(0)\r\n",
        "      self.Prob_Y[Y_index,:] = self.ProbY(Y_onevsall)   # [P(notYi), P(Yi)]\r\n",
        "      self.Prob_X_Y[Y_index,0,:] = self.ProbX_Yi(X,Y_onevsall,0)  # [P(x1|notYi), P(x2|notYi),...]\r\n",
        "      self.Prob_X_Y[Y_index,1,:] = self.ProbX_Yi(X,Y_onevsall,1)  # [P(x1|Yi), P(x2|Yi),...]\r\n",
        "      c[Y_index,:] = np.log10(self.Prob_X_Y[Y_index,1,:]/self.Prob_X_Y[Y_index,0,:])     # log(P(xj|Y=1)/P(xj|Y=0))\r\n",
        "      d[Y_index,:] = np.log10((1-self.Prob_X_Y[Y_index,1,:])/(1-self.Prob_X_Y[Y_index,0,:])) # log((1-P(xj|Y=1))/(1-P(xj|Y=0)))\r\n",
        "      self.w0[0,Y_index] = np.log10(self.Prob_Y[Y_index,1]/self.Prob_Y[Y_index,0]) + np.sum(d[Y_index,:])\r\n",
        "      self.w[Y_index,:] = c[Y_index,:] - d[Y_index,:]\r\n",
        "      Y_index += 1\r\n",
        "\r\n",
        "    print('------fit done, total time:',time.time()-t1,' -----')\r\n",
        "    # return self.Prob_Y,self.Prob_X_Y\r\n",
        "\r\n",
        "  def predict(self, X):\r\n",
        "    print('----------------------start predict---------------------')\r\n",
        "    t1 = time.time()\r\n",
        "\r\n",
        "    rows,cols = X.shape       # feature shape\r\n",
        "    PreY = np.empty((rows,1),dtype='S') # initialize Y\r\n",
        "    print('type',type(PreY))\r\n",
        "    LogOddsRatio = np.zeros((1,self.n_class))  # initialize log odds ratio a(x) \r\n",
        "    Logistic = np.zeros((1,self.n_class))    # initialize logistic function\r\n",
        "    Y_index = 0\r\n",
        "    for obs in range(rows):\r\n",
        "      for Yi in self.Ytarget:\r\n",
        "        LogOddsRatio[0,Y_index] = self.w0[0,Y_index] + np.sum((self.w[Y_index,:]*X[obs,:])) \r\n",
        "        Logistic[0,Y_index] = 1/(1+np.exp(-LogOddsRatio[0,Y_index]))\r\n",
        "        Y_index += 1\r\n",
        "      Y_index = 0\r\n",
        "      print(np.where(Logistic == np.amax(Logistic))[1])\r\n",
        "      PreY[obs] = self.Ytarget[np.where(Logistic == np.amax(Logistic))[1]]\r\n",
        "    print('------predict done, total time:',time.time()-t1,' -----')\r\n",
        "    return PreY\r\n",
        "\r\n",
        "  def Accu_eval(self,PreY,TrueY):\r\n",
        "    #y_predict = self.predict(X_test)\r\n",
        "    rows,cols = np.shape(PreY)\r\n",
        "    TP = 0;FP = 0;TN = 0;FN = 0\r\n",
        "    # count TP,TN,FP,FN in validation set\r\n",
        "    for obs in range(rows):\r\n",
        "      if  TrueY[obs]==1 and PreY[obs]==1:\r\n",
        "        TP = TP+1\r\n",
        "      elif TrueY[obs]==0 and PreY[obs]==0:\r\n",
        "        TN = TN+1\r\n",
        "      elif TrueY[obs]==0 and PreY[obs]==1:\r\n",
        "        FP = FP+1\r\n",
        "      elif TrueY[obs]==1 and PreY[obs]==0:\r\n",
        "        FN = FN+1    \r\n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\r\n",
        "    precision = TP/(TP+FP)\r\n",
        "    recall = TP/(TP+FN)\r\n",
        "    F = 2*precision*recall/(precision+recall)\r\n",
        "    specificity = TN/(FP+TN)\r\n",
        "    FPR = FP/(FP+TN)\r\n",
        "    print(\"---------------------accuracy:\",accuracy,'-------------------')\r\n",
        "    return accuracy\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DfnCeH3hCxtV",
        "outputId": "ce5936e1-2c1d-4e39-8150-4fc4331a4037"
      },
      "source": [
        "B = Bernoulli_NB()\r\n",
        "\r\n",
        "parameters = {\r\n",
        "...     'vect__ngram_range': [(1, 1), (1, 2)],\r\n",
        "...     'tfidf__use_idf': (True, False),\r\n",
        "... }\r\n",
        "\r\n",
        "B.fit(vectors_train,y_train)\r\n",
        "#PreY = B.predict(vectors_test)\r\n",
        "PreY = B.predict(vectors_train)\r\n",
        "#B.Accu_eval(PreY,Ytest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------start fitting---------------------\n",
            "------fit done, total time: 3.900989055633545  -----\n",
            "----------------------start predict---------------------\n",
            "type <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d56eb494a865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#PreY = B.predict(vectors_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mPreY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#B.Accu_eval(PreY,Ytest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-b94d04dde2fd>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mYi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mLogOddsRatio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mLogistic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mLogOddsRatio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mY_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;31m# dense row or column vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: dimension mismatch"
          ]
        }
      ]
    }
  ]
}