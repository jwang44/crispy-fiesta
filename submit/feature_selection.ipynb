{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature selection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/crispy-fiesta/blob/main/submit/feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWaq0M1Bj39x"
      },
      "source": [
        "# Feature selection after N-grams\n",
        "This notebook is for investigating the use of N-gram and various feature selection strategies. N-grams introduces a lot of redundant features, so feature selection is necessary in making the model efficient. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhYkxNMosYcz",
        "outputId": "77df4cc9-f468-4416-ea85-d9c867d4bd73"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3YXcam7SI-H"
      },
      "source": [
        "## Load the data and get basic features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVrTh5Fdsqcg"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OMqYMZNsq_-"
      },
      "source": [
        "train = pd.read_csv('./train.csv',engine='python')\r\n",
        "test = pd.read_csv('./test.csv',engine='python')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjdGixmNss4K"
      },
      "source": [
        "X_train = train.body  # train texts\r\n",
        "y_train = train.subreddit # train subreddits\r\n",
        "X_test = test.body  # test texts"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95NKm9YPtJ_d"
      },
      "source": [
        "from sklearn.preprocessing import Normalizer, LabelEncoder\r\n",
        "from sklearn.feature_extraction import text\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XFoTwA_s2B-",
        "outputId": "82209fcd-c643-4592-f78a-4a6f372b74e3"
      },
      "source": [
        "# transform target labels to values\r\n",
        "le = LabelEncoder()\r\n",
        "y_train_num = le.fit_transform(y_train.values) # convert category from string to numerical\r\n",
        "\r\n",
        "# vectorize word count\r\n",
        "vectorizer = CountVectorizer()\r\n",
        "vectors_train = vectorizer.fit_transform(X_train)\r\n",
        "vectors_test = vectorizer.transform(X_test)\r\n",
        "\r\n",
        "normalizer_train = Normalizer()\r\n",
        "vectors_train= normalizer_train.transform(vectors_train)\r\n",
        "vectors_test= normalizer_train.transform(vectors_test)\r\n",
        "\r\n",
        "# print(vectorizer.get_feature_names())\r\n",
        "print(vectors_train.shape)\r\n",
        "print(vectors_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 15365)\n",
            "(1378, 15365)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkJsrQzH1qAD",
        "outputId": "057a7782-ffb4-4a6e-ef3d-b85c0b293d96"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\r\n",
        "from nltk import word_tokenize\r\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOD25ysB1x1o",
        "outputId": "54616a67-27b9-4eb6-80bb-01f76cdf4ea1"
      },
      "source": [
        "# remove stop words and punctuation, tfidf, lemmatization, normalization\r\n",
        "stop_words = text.ENGLISH_STOP_WORDS\r\n",
        "\r\n",
        "def get_wordnet_pos(word):\r\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\r\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\r\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\r\n",
        "                \"N\": wordnet.NOUN,\r\n",
        "                \"V\": wordnet.VERB,\r\n",
        "                \"R\": wordnet.ADV}\r\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\r\n",
        "\r\n",
        "class New_LemmaTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl = WordNetLemmatizer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.lemmatize(t,pos =get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "tf_idf_transformer = TfidfTransformer()\r\n",
        "vectorizer = CountVectorizer(stop_words = stop_words, tokenizer = New_LemmaTokenizer(), ngram_range=(1, 2)) #unigram+bigram:ngram_range=(1, 2), only bigram:ngram_range=(2, 2)\r\n",
        "vectors_train_stop_tfidf_Lemma = vectorizer.fit_transform(X_train)\r\n",
        "vectors_train_stop_tfidf_Lemma = tf_idf_transformer.fit_transform(vectors_train_stop_tfidf_Lemma)\r\n",
        "vectors_test_stop_tfidf_Lemma = vectorizer.transform(X_test)\r\n",
        "vectors_test_stop_tfidf_Lemma = tf_idf_transformer.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "vectors_train_stop_tfidf_Lemma = normalizer_train.transform(vectors_train_stop_tfidf_Lemma)\r\n",
        "vectors_test_stop_tfidf_Lemma = normalizer_train.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "\r\n",
        "#print(vectorizer.get_feature_names())\r\n",
        "print(vectors_train_stop_tfidf_Lemma.shape)\r\n",
        "print(vectors_test_stop_tfidf_Lemma.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make', 'u'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1999, 70414)\n",
            "(1378, 70414)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVKDAZnflK1P"
      },
      "source": [
        "After adding bi-gram to unigram, we end up over 70,000 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oBLHbwe13Uw",
        "outputId": "7c061e9e-72aa-46d5-ad1b-62faa64834ed"
      },
      "source": [
        "# remove stopwords and punctuation, tfidf, stemming, normalization\r\n",
        "stop_words = text.ENGLISH_STOP_WORDS\r\n",
        "\r\n",
        "class StemTokenizer:\r\n",
        "     def __init__(self):\r\n",
        "       self.wnl =PorterStemmer()\r\n",
        "     def __call__(self, doc):\r\n",
        "       return [self.wnl.stem(t) for t in word_tokenize(doc) if t.isalpha()]\r\n",
        "\r\n",
        "tf_idf_transformer = TfidfTransformer()\r\n",
        "vectorizer = CountVectorizer(stop_words = stop_words, tokenizer=StemTokenizer(),ngram_range=(1, 2)) #unigram+bigram:ngram_range=(1, 2), only bigram:ngram_range=(2, 2)\r\n",
        "vectors_train_stop_tfidf_stem = vectorizer.fit_transform(X_train)\r\n",
        "vectors_train_stop_tfidf_stem = tf_idf_transformer.fit_transform(vectors_train_stop_tfidf_stem)\r\n",
        "vectors_test_stop_tfidf_stem = vectorizer.transform(X_test)\r\n",
        "vectors_test_stop_tfidf_stem = tf_idf_transformer.transform(vectors_test_stop_tfidf_stem)\r\n",
        "vectors_train_stop_tfidf_stem = normalizer_train.transform(vectors_train_stop_tfidf_stem)\r\n",
        "vectors_test_stop_tfidf_stem = normalizer_train.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stop_tfidf_stem.shape)\r\n",
        "print(vectors_test_stop_tfidf_stem.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1999, 73597)\n",
            "(1378, 73597)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcDWLcpSSQUX"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzvYQTytAXZ"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, mutual_info_classif, f_classif, SelectFpr, SelectFwe, SelectFdr, RFE, RFECV, SelectFromModel\r\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aigDmX5vOJA"
      },
      "source": [
        "### 13.2.1 chi2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iAF8SklN6_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ad425a-9c1c-4f2d-d577-337b9b071a27"
      },
      "source": [
        "# choose one: SelectPercentile percent%, selectkbest abolute number\r\n",
        "select = SelectPercentile(chi2, percentile=60)\r\n",
        "vectors_train_Lemma_X2 = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_X2 = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_X2.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 42248)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA2BenS0vP2c",
        "outputId": "d6de3165-f40d-4b8c-88fb-6ab87cdc5339"
      },
      "source": [
        "select = SelectKBest(chi2, k=6000)\r\n",
        "vectors_train_Lemma_X2 = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_X2 = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_X2.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 6000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBA011sCOXkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7e33f7-268d-47fd-e1f9-fc3a88376473"
      },
      "source": [
        "select = SelectPercentile(chi2, percentile=60)\r\n",
        "vectors_train_stem_X2 = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_X2 = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_X2.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 44158)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fofG4Jh43IPk",
        "outputId": "c04930f6-b239-4e88-b40b-85dda1dc806d"
      },
      "source": [
        "select = SelectKBest(chi2, k=5000)\r\n",
        "vectors_train_stem_X2 = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_X2 = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_X2.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wfWxVDLwIgJ"
      },
      "source": [
        "### 13.2.2 mutual info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfa6Ng5zP1MK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e257023-02de-4869-a443-daa485f9935c"
      },
      "source": [
        "select = SelectPercentile(mutual_info_classif, percentile=60)\r\n",
        "vectors_train_Lemma_X2 = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_X2 = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_X2.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 42248)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5hcm_khwIIc",
        "outputId": "facd8f27-8d4e-410c-aa11-1dfdc8df11aa"
      },
      "source": [
        "select = SelectKBest(mutual_info_classif, k=6000)\r\n",
        "vectors_train_Lemma_mutual = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_mutual = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_mutual.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 6000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEtpmQksP6cN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922d4799-0266-477d-fcc5-3adfa05b9014"
      },
      "source": [
        "select = SelectPercentile(mutual_info_classif, percentile=60)\r\n",
        "vectors_train_stem_X2 = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_X2 = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_X2.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 44158)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7gyVxTQ3qxU",
        "outputId": "1305855e-3438-46bd-f528-43cc873e7414"
      },
      "source": [
        "select = SelectKBest(mutual_info_classif, k=6000)\r\n",
        "vectors_train_stem_mutual = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_mutual = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_mutual.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 6000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiZEnhPZ0HnK"
      },
      "source": [
        "### 13.2.3 F score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LCiPkB6Q3jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3782a7-536a-404f-a095-83b3cb56c651"
      },
      "source": [
        "select = SelectPercentile(f_classif, percentile=60)\r\n",
        "vectors_train_Lemma_X2 = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_X2 = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_X2.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 42248)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K159Gmtz0Aww",
        "outputId": "55f191a5-b1d3-44e1-8e9c-b8e9bf7e4935"
      },
      "source": [
        "select = SelectKBest(f_classif, k=6000)\r\n",
        "vectors_train_Lemma_F = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_F = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_F.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 6000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjmQ7tSiSGsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166fa3c8-7524-4c4e-ccd6-e04c018b61d0"
      },
      "source": [
        "select = SelectPercentile(f_classif, percentile=60)\r\n",
        "vectors_train_stem_X2 = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_X2 = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_X2.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 44158)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz0kpHEp4JrN",
        "outputId": "16242587-b733-40f1-a345-b5ff8261878d"
      },
      "source": [
        "select = SelectKBest(f_classif, k=6000)\r\n",
        "vectors_train_stem_F = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_F = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "print(vectors_train_stem_F.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 6000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNY9UPfohXAh"
      },
      "source": [
        "### 13.2.4 FPR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CrHP_mShXWV",
        "outputId": "8c84767c-a39a-42df-8753-4573da6082db"
      },
      "source": [
        "select = SelectFpr()\r\n",
        "vectors_train_Lemma_FPR = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_FPR = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "vectors_train_Lemma_FPR.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 2602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsmNj4QLjol3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2829678c-34aa-476c-f64b-826f95d0e4f3"
      },
      "source": [
        "select = SelectFpr()\r\n",
        "vectors_train_stem_FPR = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_FPR = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "vectors_train_stem_FPR.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 2770)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMy4Tp48j0nn"
      },
      "source": [
        "### 13.2.5 FDR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2K05LInjy3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bdb03c-11da-4df0-8cd1-194753b13265"
      },
      "source": [
        "select = SelectFdr()\r\n",
        "vectors_train_Lemma_FDR = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_FDR = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "vectors_train_Lemma_FDR.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 1013)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea3uI8_fiex7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f669052-af43-4a81-850a-e98da34e539f"
      },
      "source": [
        "select = SelectFdr()\r\n",
        "vectors_train_stem_FDR = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_FDR = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "vectors_train_stem_FDR.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 1064)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ovjGEulUlv"
      },
      "source": [
        "### 13.2.6 FWE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eizM4rbzh3gC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b241082-daf2-44b7-d0f2-c2eadccff512"
      },
      "source": [
        "select = SelectFwe()\r\n",
        "vectors_train_Lemma_FWE = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_FWE = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "vectors_train_Lemma_FWE.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 507)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dht3JAVlplI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab36f654-1347-44ab-c347-4bed22fe752e"
      },
      "source": [
        "select = SelectFwe()\r\n",
        "vectors_train_stem_FWE = select.fit_transform(vectors_train_stop_tfidf_stem, y_train_num)\r\n",
        "vectors_test_stem_FWE = select.transform(vectors_test_stop_tfidf_stem)\r\n",
        "vectors_train_stem_FWE.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 523)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4imy8E_6ALI"
      },
      "source": [
        "### 13.3 Recursive feature elimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGqifNt8XY7"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.svm import SVC, LinearSVC\r\n",
        "\r\n",
        "from sklearn.model_selection import KFold, cross_val_score"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndYrr7lLUPo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d31012a-bd1b-41a7-fad8-a3f8494e6815"
      },
      "source": [
        "estimator = LinearSVC()\r\n",
        "select = RFECV(estimator, step=700,scoring='accuracy')\r\n",
        "vectors_train_Lemma_RFESVC = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_RFESVC = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_RFESVC.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 18614)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W39u3IvUYa-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e60dc9-0aa7-4cc5-e132-5869baa52813"
      },
      "source": [
        "estimator = LogisticRegression()\r\n",
        "select = RFECV(estimator, step=700,scoring='accuracy')\r\n",
        "vectors_train_Lemma_RFELR = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_RFELR = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_RFELR.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 19314)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A40g9do-ZqjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6987c27c-dcd6-4f0f-963b-3a13b19b096a"
      },
      "source": [
        "estimator = MultinomialNB()\r\n",
        "select = RFECV(estimator, step=700,scoring='accuracy')\r\n",
        "vectors_train_Lemma_RFEMNB = select.fit_transform(vectors_train_stop_tfidf_Lemma, y_train_num)\r\n",
        "vectors_test_Lemma_RFEMNB = select.transform(vectors_test_stop_tfidf_Lemma)\r\n",
        "print(vectors_train_Lemma_RFEMNB.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 70414)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4bpJ3t0TMnS"
      },
      "source": [
        "## Experiment on sklearn models (with NGRAM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L41zKhUPVj2l"
      },
      "source": [
        "### Find the best set of features\n",
        "As stem has basically the same effect as Lemma, we only keep Lemma for further experiments\n",
        "\n",
        "\n",
        "The best are \n",
        "\n",
        "vectors_train_Lemma_X2\n",
        "\n",
        "vectors_train_Lemma_F\n",
        "\n",
        "vectors_train_Lemma_RFESVC/RFELR/RFEMNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZQ1dRU4yIpa",
        "outputId": "8927b836-14d4-4f09-8350-8debb9552fbf"
      },
      "source": [
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_X2, y_train_num, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_mutual, y_train_num, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_F, y_train_num, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FPR, y_train_num, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FDR, y_train_num, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FWE, y_train_num, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LinearSVC()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_RFESVC, y_train_num, cv=5)\n",
        "print(scores.mean())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9399736842105263\n",
            "0.9319636591478696\n",
            "0.9464736842105262\n",
            "0.9359674185463659\n",
            "0.9199523809523811\n",
            "0.8864335839598997\n",
            "0.9384661654135338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctlyl4oiUzMf",
        "outputId": "8c5f3c31-4403-445a-986e-139800e17273"
      },
      "source": [
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_X2, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_mutual, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_F, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FPR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FDR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FWE, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_RFELR, y_train_num, cv=10)\n",
        "print(scores.mean())\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9364798994974877\n",
            "0.9289748743718593\n",
            "0.9374773869346734\n",
            "0.9329723618090451\n",
            "0.9079522613065327\n",
            "0.8809472361809044\n",
            "0.9319773869346735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xreyyyy0fa3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4575ab25-d2bf-4885-8e85-d53fb0c682b6"
      },
      "source": [
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_X2, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_mutual, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_F, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FPR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FDR, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_FWE, y_train_num, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, vectors_train_Lemma_RFEMNB, y_train_num, cv=10)\n",
        "print(scores.mean())\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9179673366834171\n",
            "0.9164673366834171\n",
            "0.9329723618090451\n",
            "0.9159698492462311\n",
            "0.8879497487437185\n",
            "0.8354246231155777\n",
            "0.9204698492462311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq5zBLuWWSQH"
      },
      "source": [
        "### Grid search\n",
        "The best features:\n",
        "\n",
        "vectors_train_Lemma_X2\n",
        "\n",
        "vectors_train_Lemma_F\n",
        "\n",
        "vectors_train_Lemma_RFESVC/RFELR/RFEMNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrmAJbRtXGNC"
      },
      "source": [
        "#### vectors_train_Lemma_X2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB20XzS3FqBL"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IzciLosEMMi",
        "outputId": "493a6296-21a4-47f7-c0a0-f9e8e7f9200f"
      },
      "source": [
        "model = LinearSVC()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_X2, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9459798994974875\n",
            "C: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZxIyqcWQC6u",
        "outputId": "5cb40255-86c4-4556-a7ce-574f8348231e"
      },
      "source": [
        "model = MultinomialNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2), \n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_X2, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9554849246231155\n",
            "alpha: 1e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFaBCtA8wzVA",
        "outputId": "816b4cfb-4537-47b6-bac1-eec1ac766208"
      },
      "source": [
        "model = LogisticRegression()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_X2, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9399773869346735\n",
            "C: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQn11XdNXc89"
      },
      "source": [
        "#### vectors_train_Lemma_F"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzPswnO0XrO_"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mqy1F4cXrPL",
        "outputId": "90ef0a15-624b-411b-bafd-d5bff2aef902"
      },
      "source": [
        "model = LinearSVC()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_F, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9469748743718593\n",
            "C: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYZmNzgMXrPN",
        "outputId": "c333e70a-15c7-46d9-a035-ec0c6572d0e0"
      },
      "source": [
        "model = MultinomialNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2), \n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_F, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9639874371859296\n",
            "alpha: 1e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1zYdzDxXrPO",
        "outputId": "b035ea64-170d-49b0-d59d-27767d220778"
      },
      "source": [
        "model = LogisticRegression()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_X2, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9399773869346735\n",
            "C: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4zY3GidX5ak"
      },
      "source": [
        "#### vectors_train_Lemma_RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v2HbixzX8GN"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjO6eBlQX8GY",
        "outputId": "165fc8ea-212f-4c02-ac59-fcf1fc41f2a3"
      },
      "source": [
        "model = LinearSVC()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_RFESVC, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9439723618090451\n",
            "C: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TjSc2XjX8Gb",
        "outputId": "479ffa7a-954b-4be0-e356-7b8ae4808d4b"
      },
      "source": [
        "model = MultinomialNB()\n",
        "parameters = {\n",
        "    'alpha': (1e-10, 1e-5, 0.1, 0.5, 1, 2), \n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_RFEMNB, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9304723618090451\n",
            "alpha: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEHjQk3iX8Gb",
        "outputId": "2f13a69c-8d94-40ec-acc0-0e750ef55a2e"
      },
      "source": [
        "model = LogisticRegression()\n",
        "parameters = {\n",
        "    'C': (0.01, 0.1, 1, 10, 100, 1000)\n",
        "}\n",
        "gs_model = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
        "gs_model = gs_model.fit(vectors_train_Lemma_RFELR, y_train_num)\n",
        "print(gs_model.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_model.best_params_[param_name]))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9414773869346735\n",
            "C: 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBZ16L91cGK7"
      },
      "source": [
        "### Best model: LinearSVM on vectors_train_Lemma_X2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qVb0ydkdAS3"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z3MyfeQVs7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a295391f-4973-4738-e8a0-575a9e1ca1b9"
      },
      "source": [
        "model = LinearSVC(C=1)\n",
        "cross_val_score(model, vectors_train_Lemma_X2, y_train_num, cv=10)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.92      , 0.97      , 0.95      , 0.94      , 0.92      ,\n",
              "       0.935     , 0.965     , 0.955     , 0.945     , 0.95979899])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IFZ5fY6V_Ca"
      },
      "source": [
        "model = LinearSVC(C=1)\n",
        "model.fit(vectors_train_Lemma_X2, y_train_num)\n",
        "y_pred = model.predict(vectors_test_Lemma_X2)\n",
        "y_pred = le.inverse_transform(y_pred)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz9rCLvRkKDB"
      },
      "source": [
        "#### Write results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYiVSRFSiKw-"
      },
      "source": [
        "result = pd.DataFrame({'id': test.id, 'subreddit': y_pred})\n",
        "result.to_csv(\"result.csv\", index=False)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfs8FKWxWIbM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "05326183-75ee-44ed-8c71-b88052a362fb"
      },
      "source": [
        "pred_csv = pd.read_csv('result.csv',engine='python')\n",
        "pred_csv.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>anime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id subreddit\n",
              "0   0   science\n",
              "1   1   science\n",
              "2   2     anime\n",
              "3   3   science\n",
              "4   4   science"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv-LNm10CaLk"
      },
      "source": [
        "### Second Best model: MultiNB on vectors_train_Lemma_F"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uK_TB7_CaLo"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwCBQu6CCaLp",
        "outputId": "ca55b28c-00a3-450f-bffc-56dbd4d82f8b"
      },
      "source": [
        "model = MultinomialNB(alpha=1e-5)\n",
        "cross_val_score(model, vectors_train_Lemma_F, y_train_num, cv=10)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96      , 0.985     , 0.95      , 0.975     , 0.94      ,\n",
              "       0.965     , 0.98      , 0.955     , 0.955     , 0.97487437])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vCDdoN6CaLq"
      },
      "source": [
        "model = MultinomialNB(alpha=1e-5)\n",
        "model.fit(vectors_train_Lemma_F, y_train_num)\n",
        "y_pred = model.predict(vectors_test_Lemma_F)\n",
        "y_pred = le.inverse_transform(y_pred)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acrbVwmaCaLq"
      },
      "source": [
        "#### Write results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcAJg9XFCaLr"
      },
      "source": [
        "result = pd.DataFrame({'id': test.id, 'subreddit': y_pred})\n",
        "result.to_csv(\"result.csv\", index=False)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FA1Jr0nrCaLs",
        "outputId": "3cbc5303-7fec-4eb5-d6e3-a96fdfa358fb"
      },
      "source": [
        "pred_csv = pd.read_csv('result.csv',engine='python')\n",
        "pred_csv.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>laptop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id subreddit\n",
              "0   0   science\n",
              "1   1   science\n",
              "2   2    laptop\n",
              "3   3   science\n",
              "4   4   science"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}